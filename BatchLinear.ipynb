{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dependencies\n",
    "import os\n",
    "from csv import reader\n",
    "import random\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pw/Desktop/Machine Learning/mlwork'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the working directory\n",
    "os.getcwd()\n",
    "os.chdir(\"/Users/pw/Desktop/Machine Learning/mlwork\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The csv function for uploading the file\n",
    "def csv_upload(filename):\n",
    "    dataset = []\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        csv_reader = reader(csv_file, delimiter =',')\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "        del dataset[0]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading the csv file\n",
    "iris = csv_upload('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.9', '3', '1.4', '0.2', 'setosa']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.9', '3', '1.4', '0.2', 'setosa']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = iris\n",
    "data_file[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.9', '3', '1.4', '0.2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete the fourth column\n",
    "for row in data_file:\n",
    "    del row[4]\n",
    "data_file[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change all values from string to float\n",
    "def string_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.1, 3.5, 1.4, 0.2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in range(len(data_file[0])):\n",
    "    string_to_float(data_file, c)\n",
    "data_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the dataset\n",
    "random.shuffle(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.6, 3.2, 1.4, 0.2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling ~ The minimax function\n",
    "def mini_max(dataset):\n",
    "    minimax = []\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        min_value = min(col_values)\n",
    "        max_value = max(col_values)\n",
    "        minimax.append([min_value, max_value])\n",
    "    return minimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4.3, 7.9], [2.0, 4.4], [1.0, 6.9], [0.1, 2.5]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_max = mini_max(data_file)\n",
    "mini_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data using the minimax normalization\n",
    "def minmax_normalization(dataset, minimax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(dataset[0])):\n",
    "            row[i] = (row[i] - minimax[i][0]) / (minimax[i][1] - minimax[i][0])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08333333333333327, 0.5, 0.06779661016949151, 0.04166666666666667]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_file = minmax_normalization(data_file,mini_max)\n",
    "norm_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
       "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
       "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
       "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
       "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the test and train data sets\n",
    "file_array =np.asarray(norm_file)\n",
    "file_array[0:5,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72881356, 0.74576271, 0.15254237, 0.03389831, 0.6779661 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y = file_array[0:120, 2]\n",
    "test_Y = file_array[121:,2]\n",
    "test_Y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = file_array[0:120, 0]\n",
    "test_X = file_array[121:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The batch gradient descent algorithm\n",
    "def gradient_descent(x, y, alpha, max_error = 0.001, max_iterations = 10000):\n",
    "    coef = []\n",
    "    converged = False\n",
    "    iter = 0\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    #Initializing the firts theta's\n",
    "    theta0 = 0.1\n",
    "    theta1 = 0.1\n",
    "    \n",
    "    #Initial error\n",
    "    \n",
    "    Jtheta = sum([(theta0 + theta1*x[i]-y[i])**2 for i in range(m)])\n",
    "    \n",
    "    while not converged:\n",
    "        #calculating the updates\n",
    "        grad0 = 1/m * sum([(theta0 + theta1 * x[i] - y[i])for i in range(m)])\n",
    "        grad1 = 1/m * sum([(theta0 + theta1 * x[i] - y[i]) * x[i] for i in range(m)])\n",
    "        \n",
    "        #updating the coeffients\n",
    "        \n",
    "        theta0 = theta0 - alpha*grad0\n",
    "        theta1 = theta1 - alpha*grad1\n",
    "        \n",
    "        e = sum([(theta0 + theta1*x[i] - y[i])**2 for i in range(m)])\n",
    "        \n",
    "        #Exiting loop / Termination condition\n",
    "        \n",
    "        if abs(Jtheta-e) <= max_error:\n",
    "            print(\"Converged, number of iteration\", iter)\n",
    "            converged = True\n",
    "        Jtheta = e\n",
    "        iter += 1\n",
    "        \n",
    "        if iter == max_iterations:\n",
    "            print('Maximum number of iterations reached')\n",
    "            converged = true\n",
    "    coef.append(theta0)\n",
    "    coef.append(theta1)\n",
    "    return coef\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the prediction function\n",
    "def predict(x, coef):\n",
    "    predicted = list()\n",
    "    m = x.shape[0]\n",
    "    for i in range(m):\n",
    "        predict = coef[0] + coef[1]*x[i]\n",
    "        predicted.append(predict)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged, number of iteration 4162\n"
     ]
    }
   ],
   "source": [
    "coef = gradient_descent(train_X, train_Y,0.01, max_error = 0.0001, max_iterations = 10000)\n",
    "predicted = predict(train_X, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
