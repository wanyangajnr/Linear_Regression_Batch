{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Starting Synaptic weights\n",
      "Layer 1: 4 neuron each with 4 inputs: \n",
      "[[8.34044009e-01 1.44064899e+00 2.28749635e-04 6.04665145e-01]\n",
      " [2.93511782e-01 1.84677190e-01 3.72520423e-01 6.91121454e-01]\n",
      " [7.93534948e-01 1.07763347e+00 8.38389029e-01 1.37043900e+00]\n",
      " [4.08904499e-01 1.75623487e+00 5.47751864e-02 1.34093502e+00]]\n",
      "Layer 2: 1 neuron with 4 inputs: \n",
      "[[0.8346096 ]\n",
      " [1.11737966]\n",
      " [0.28077388]\n",
      " [0.39620298]]\n",
      "5.459489999999995\n",
      "Stage 2 Weights\n",
      "Layer 1: 4 neuron each with 4 inputs: \n",
      "[[-0.63876753  6.07311882 -3.52308994  2.35496609]\n",
      " [ 8.39021154 -1.23502428  1.57507031  2.54357351]\n",
      " [ 0.82184987 -1.99623784  0.79242336  3.71004044]\n",
      " [-3.45090934  4.50332047 -1.43641378  3.53021843]]\n",
      "Layer 2: 1 neuron with 4 inputs: \n",
      "[[  9.82492045]\n",
      " [  7.32092522]\n",
      " [ -3.44942274]\n",
      " [-12.3057168 ]]\n",
      "Stage 3 for a new siatuation\n",
      "[[0.67549753]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import exp, dot, array, random\n",
    "import time\n",
    "class neuronLayer():\n",
    "    \n",
    "    def __init__(self, numberOfNeurons, inputsPerNeuron):\n",
    "        self.synapticWeights = 2 * random.random((inputsPerNeuron, numberOfNeurons))\n",
    "\n",
    "class neuralNetwork():\n",
    "    \n",
    "    def __init__(self, layer1, layer2):\n",
    "        \n",
    "        self.layer1 = layer1\n",
    "        self.layer2 = layer2\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #The sigmoid function\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1+exp(-x))\n",
    "        \n",
    "    #The sigmoid derivative\n",
    "    def sigmoidDerivative(self, x):\n",
    "        return x*(1-x)\n",
    "      \n",
    "    #The network\n",
    "    def train(self, trainIn, trainOut, maxIter):\n",
    "            \n",
    "        #Passing the train inputs through the network\n",
    "        start=  time.process_time()     \n",
    "        for iteration in range(maxIter):\n",
    "                \n",
    "            output1, output2 = self.think(trainIn)\n",
    "                \n",
    "            # getting the error and the adjustment value\n",
    "                \n",
    "            error2 = trainOut - output2\n",
    "            delta2 = error2 * self.sigmoidDerivative(output2)\n",
    "                \n",
    "            # getting the error and adjustment value for error1 \n",
    "            # error1 is determined by looking at how much layer 1 contributed to the error / delta in layer 2\n",
    "            #this is achieved by multiplying the delta in layer 2 by the weights in layer 1\n",
    "            error1 = delta2.dot(self.layer2.synapticWeights.T) # TBC\n",
    "            delta1 = error1 * self.sigmoidDerivative(output1)\n",
    "                \n",
    "            # Calculate by how much you adjust the weights\n",
    "            layer1Adjustment = trainIn.T.dot(delta1)\n",
    "            layer2Adjustment = output1.T.dot(delta2)\n",
    "                \n",
    "            #Adjust the weights\n",
    "            self.layer1.synapticWeights += layer1Adjustment\n",
    "            self.layer2.synapticWeights += layer2Adjustment\n",
    "   \n",
    "        print(time.process_time()- start)\n",
    "    \n",
    "    \n",
    "    def think(self, inputs):\n",
    "        output1 = self.sigmoid(dot(inputs, self.layer1.synapticWeights))\n",
    "        output2 = self.sigmoid(dot(output1, self.layer2.synapticWeights))\n",
    "            \n",
    "        return output1, output2\n",
    "            \n",
    "            \n",
    "    #The neural network prints its weights\n",
    "        \n",
    "    def printWeights(self):\n",
    "        print(\"Layer 1: 4 neuron each with 4 inputs: \")\n",
    "        print(self.layer1.synapticWeights)\n",
    "            \n",
    "        print(\"Layer 2: 1 neuron with 4 inputs: \")\n",
    "        print(self.layer2.synapticWeights)\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #Seed the random generator\n",
    "    \n",
    "    random.seed(1)\n",
    "    \n",
    "    #Create the layers\n",
    "    \n",
    "    layer1 = neuronLayer(4,4)\n",
    "    layer2 = neuronLayer(1,4)\n",
    "    \n",
    "    #Create the neural network\n",
    "    \n",
    "    neuralNetwork = neuralNetwork(layer1,layer2)\n",
    "    \n",
    "    print(\"Random Starting Synaptic weights\")\n",
    "    \n",
    "    neuralNetwork.printWeights()\n",
    "    \n",
    "    trainIn = array([[0,1,1,1],[1,0,1,0],[1,0,1,0],[0,0,1,1],[1,1,1,1],[0,1,1,0],[1,0,0,1],[0,1,1,1],[0,1,1,1]])\n",
    "    trainOut = array([[1,0,1,0,1,0,0,0,1]]).T\n",
    "    \n",
    "    neuralNetwork.train(trainIn, trainOut, 60000)\n",
    "    \n",
    "    print(\"Stage 2 Weights\")\n",
    "    \n",
    "    neuralNetwork.printWeights()\n",
    "    \n",
    "    print(\"Stage 3 for a new siatuation\")\n",
    "    \n",
    "    hState, output = neuralNetwork.think(array([[0,1,1,1]]))\n",
    "    \n",
    "    print(output)\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
